{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating spiking neurons with Tensorflow\n",
    "\n",
    "In this notebook, we try to simulate a population of spiking neurons using Tensorflow.\n",
    "\n",
    "This exercise is based on an equivalent exercise using [Matlab](http://www.mjrlab.org/wp-content/uploads/2014/05/CSHA_matlab_2012.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking neuron model\n",
    "\n",
    "The neuron model is based on [\"Simple model on spiking neuron\"](http://www.izhikevich.org/publications/spikes.htm), by Eugene M. Izhikevich.\n",
    "\n",
    "<img src=\"izhik.gif\">\n",
    "\n",
    "Electronic version of the figure and reproduction permissions are freely available at www.izhikevich.com\n",
    "\n",
    "The behaviour of the neuron is determined by its membrane potential v that increases over time when it is stimulated by an input current I.\n",
    "Whenever the membrane potential reaches the spiking threshold, the membrane potential is reset.\n",
    "\n",
    "The membrane potential increase is mitigated by an adversary recovery effect defined by the u variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow doesn't support differential equations, so we need to approximate the evolution of the membrane potential and\n",
    "membrane recovery by evaluating their variations over small time intervals dt:\n",
    "\n",
    "$$dv = 0.04v^2 + 5v + 140 -u + I$$\n",
    "\n",
    "$$du = a(bv -u)$$\n",
    "\n",
    "We can then apply the variations by multiplying by the time interval dt:\n",
    "\n",
    "$$v += dv.dt$$\n",
    "\n",
    "$$u += du.dt$$\n",
    "    \n",
    "As stated in the model, the $0.04$, $5$ and $140$ values have been defined so that $v$ is in $mV$, $I$ is in $A$ and $t$ in $ms$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a single neuron with injected current\n",
    "\n",
    "In a first step, we stimulate the neuron model with a square input current."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# A class representing a population of simple neurons\n",
    "#\n",
    "class SimpleNeurons(object):\n",
    "    \n",
    "    def __init__(self, n=1, A=None, B=None, C=None, D=None):\n",
    "\n",
    "        ####################\n",
    "        # Model parameters #\n",
    "        ####################\n",
    "\n",
    "        # The number of neurons\n",
    "        self.n = n\n",
    "\n",
    "        # Scale of the membrane recovery (lower values lead to slow recovery)\n",
    "        if A is None:\n",
    "            self.A = np.full((n), 0.02, dtype=np.float32)\n",
    "        else:\n",
    "            self.A = A\n",
    "        # Sensitivity of recovery towards membrane potential (higher values lead to higher firing rate)\n",
    "        if B is None:\n",
    "            self.B = np.full((n), 0.2, dtype=np.float32)\n",
    "        else:\n",
    "            self.B = B\n",
    "        # Membrane voltage reset value\n",
    "        if C is None:\n",
    "            self.C = np.full((n), -65.0, dtype=np.float32)\n",
    "        else:\n",
    "            self.C = C\n",
    "        # Membrane recovery 'boost' after a spike\n",
    "        if D is None:\n",
    "            self.D = np.full((n), 8.0, dtype=np.float32)\n",
    "        else:\n",
    "            self.D = D\n",
    "        # Spiking threshold\n",
    "        self.SPIKING_THRESHOLD = 35.0\n",
    "        # Resting potential\n",
    "        self.RESTING_POTENTIAL = -70.0\n",
    "        \n",
    "        # Instantiate a specific tensorflow graph for the Neuron Model\n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        ################################\n",
    "        # Build the neuron model graph #\n",
    "        ################################\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            ##############################\n",
    "            # Variables and placeholders #\n",
    "            ##############################    \n",
    "            self.get_vars_and_ph()\n",
    "            \n",
    "            ##############\n",
    "            # Operations #\n",
    "            ##############\n",
    "            \n",
    "            # Operations to evaluate the membrane response (potential v and recovery u)\n",
    "            self.potential, self.recovery = self.get_response_ops()\n",
    "\n",
    "    ###############################################\n",
    "    # Define the graph Variables and placeholders #\n",
    "    ###############################################\n",
    "    def get_vars_and_ph(self):\n",
    "        \n",
    "            # Membrane potential\n",
    "            # All neurons start at the resting potential\n",
    "            self.v = tf.Variable(tf.constant(self.RESTING_POTENTIAL, shape=[self.n]), name='v')\n",
    "\n",
    "            # Membrane recovery\n",
    "            # All neurons start with a value of B * C\n",
    "            self.u = tf.Variable(self.B*self.C, name='u')\n",
    "\n",
    "            # We need a placeholder to pass the input current\n",
    "            self.I = tf.placeholder(tf.float32, shape=[self.n])\n",
    "\n",
    "            # We also need a placeholder to pass the length of the time interval\n",
    "            self.dt = tf.placeholder(tf.float32)\n",
    "            \n",
    "    #######################################################\n",
    "    # Define the graph of operations to update v and u:   # \n",
    "    # has_fired_op                                        # \n",
    "    #   -> (v_reset_op, u_rest_op)      <- I              #\n",
    "    #      -> (dv_op, du_op)          <- i_op             #\n",
    "    #        -> (v_op, u_op)                              #\n",
    "    # We only need to return the leaf operations as their #\n",
    "    # graph include the others.                           #\n",
    "    #######################################################\n",
    "    \n",
    "    # This method for future use when we introduce synaptic currents\n",
    "    def get_input_ops(self, has_fired_op, v_op):\n",
    "        \n",
    "        return tf.add(self.I, 0.0)\n",
    "\n",
    "    def get_response_ops(self):\n",
    "\n",
    "        has_fired_op, v_reset_op, u_reset_op = self.get_reset_ops()\n",
    "        \n",
    "        i_op = self.get_input_ops(has_fired_op, v_reset_op)\n",
    "        \n",
    "        v_op, u_op = self.get_update_ops(has_fired_op, v_reset_op, u_reset_op, i_op)\n",
    "        \n",
    "        return v_op, u_op\n",
    "\n",
    "    def get_reset_ops(self):\n",
    "        \n",
    "        # Evaluate which neurons have reached the spiking threshold\n",
    "        has_fired_op = tf.greater_equal(self.v, tf.constant(self.SPIKING_THRESHOLD, shape=[self.n]))\n",
    "    \n",
    "        # Neurons that have spiked must be reset, others simply evolve from their initial value\n",
    "\n",
    "        # Membrane potential is reset to C\n",
    "        v_reset_op = tf.where(has_fired_op, self.C, self.v)\n",
    "\n",
    "        # Membrane recovery is increased by D \n",
    "        u_reset_op = tf.where(has_fired_op, tf.add(self.u, self.D), self.u)\n",
    "\n",
    "        return has_fired_op, v_reset_op, u_reset_op\n",
    "        \n",
    "    def get_update_ops(self, has_fired_op, v_reset_op, u_reset_op, i_op):\n",
    "        \n",
    "        # Evaluate membrane potential increment for the considered time interval\n",
    "        # dv = 0 if the neuron fired, dv = 0.04v*v + 5v + 140 + I -u otherwise\n",
    "        dv_op = tf.where(has_fired_op,\n",
    "                         tf.zeros(self.v.shape),\n",
    "                         tf.subtract(tf.add_n([tf.multiply(tf.square(v_reset_op), 0.04),\n",
    "                                               tf.multiply(v_reset_op, 5.0),\n",
    "                                               tf.constant(140.0, shape=[self.n]),\n",
    "                                               i_op]),\n",
    "                                     self.u))\n",
    "            \n",
    "        # Evaluate membrane recovery decrement for the considered time interval\n",
    "        # du = 0 if the neuron fired, du = a*(b*v -u) otherwise\n",
    "        du_op = tf.where(has_fired_op,\n",
    "                         tf.zeros([self.n]),\n",
    "                         tf.multiply(self.A, tf.subtract(tf.multiply(self.B, v_reset_op), u_reset_op)))\n",
    "    \n",
    "        # Increment membrane potential, and clamp it to the spiking threshold\n",
    "        # v += dv * dt\n",
    "        v_op = tf.assign(self.v, tf.minimum(tf.constant(self.SPIKING_THRESHOLD, shape=[self.n]),\n",
    "                                                 tf.add(v_reset_op, tf.multiply(dv_op, self.dt))))\n",
    "\n",
    "        # Decrease membrane recovery\n",
    "        u_op = tf.assign(self.u, tf.add(u_reset_op, tf.multiply(du_op, self.dt)))\n",
    "\n",
    "        return v_op, u_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Simulation #\n",
    "##############\n",
    "\n",
    "# Array of input current values\n",
    "I_in = []\n",
    "# Array of evaluated membrane potential values\n",
    "v_out = []\n",
    "# Duration of the simulation in ms\n",
    "T = 1000\n",
    "# Duration of each time step in ms\n",
    "dt = 0.5\n",
    "# Number of iterations = T/dt\n",
    "steps = range(int(T / dt))\n",
    "\n",
    "# Instantiate the population of neurons (here a single one)\n",
    "neurons = SimpleNeurons(n=1)\n",
    "    \n",
    "with tf.Session(graph=neurons.graph) as sess:\n",
    "\n",
    "    # Initialize global variables to their default values \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Run the simulation at each time step\n",
    "    for step in steps:\n",
    "        \n",
    "        t = step*dt\n",
    "\n",
    "        # We generate a current step of 7 A between 200 and 700 ms\n",
    "        if t > 200 and t < 700:\n",
    "            i_in = 7.0\n",
    "        else:\n",
    "            i_in = 0.0\n",
    "            \n",
    "        # Create the dictionary of parameters to use for this time step\n",
    "        feed = {neurons.I: np.full((1), i_in), neurons.dt: [dt]}\n",
    "        \n",
    "        # Run the neuron response operations, passing our parameters\n",
    "        v, u = sess.run([neurons.potential, neurons.recovery], feed_dict=feed)\n",
    "        \n",
    "        # Store values\n",
    "        I_in.append((t, i_in))\n",
    "        v_out.append((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] =(12,6)\n",
    "# Draw the input current and the membrane potential\n",
    "plt.figure()\n",
    "plt.title('Input current')\n",
    "plt.ylabel('Current (mA)')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.plot(*zip(*I_in))\n",
    "plt.figure()\n",
    "plt.title('Neuron response')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.plot(*zip(*v_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neuron spikes at regular intervals. After each spike, the neuron membrane goes to its resting potential\n",
    "before starting to increase again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Simulate a single neuron with synaptic input\n",
    "\n",
    "It is a simple variation of the previous experiment, where the input current is the composition of currents coming from several synapses (typically here, a hundred).\n",
    "\n",
    "The formula for evaluating the synaptic current corresponds to the weighted sum of the input current generated by each synapse:\n",
    "\n",
    "$$Isyn = \\sum_{j}^{}w_{in}(j).Isyn(j)$$\n",
    "\n",
    "The current $Isyn(j)$ generated by each synapse is the multiplication of:\n",
    "- a linear response to the membrane potential, with a target objective of potential $E_{in}(j)$: ($E_{in}(j) -v$)\n",
    "- a conductance dynamics parameter, that is an exponential function $g_{in}(j)$ that is defined by a differential equation.\n",
    "\n",
    "$$\\frac{dg_{in}(j)}{dt} = \\frac{g_{in}(j)}{tau}$$\n",
    "\n",
    "Each input synapse emits a spike following a poisson distribution of frequency $frate$. The probability that a neuron fires during the time interval $dt$ is thus $frate.dt$.\n",
    "\n",
    "To simulate the neuron, we draw random numbers r in the $[0,1]$ interval at each timestep, and is the number $r$ is less than $frate.dt$, we generate a synapse spike by increasing the conductance dynamics for that synapse:\n",
    "\n",
    "$$g_{in}(j) = g_{in}(j) + 1$$\n",
    "\n",
    "The complete synaptic current formula at each timestep is:\n",
    "\n",
    "$$Isyn = \\sum_{j}^{}w_{in}(j)g_{in}(j)(E_{in}(j) -v(t)) = \\sum_{j}^{}w_{in}(j)g_{in}(j)E_{in}(j) - (\\sum_{j}w_{in}(j)g_{in}(j)).v(t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# A class representing a population of simple neurons with synaptic inputs\n",
    "#\n",
    "class SimpleSynapticNeurons(SimpleNeurons):\n",
    "    \n",
    "    def __init__(self, n=1, m=100, A=None, B=None, C=None, D=None, W_in=None):\n",
    "        \n",
    "        # Additional model parameters\n",
    "        self.m = m\n",
    "        self.tau = 10.0\n",
    "        if W_in is None:\n",
    "            self.W_in = np.full((n,m), 0.07, dtype=np.float32)\n",
    "        else:\n",
    "            self.W_in = W_in\n",
    "        # The reason this one is different is to allow broadcasting when subtracting v\n",
    "        self.E_in = np.zeros((m), dtype=np.float32)\n",
    "        \n",
    "        # Call the parent contructor\n",
    "        # This will call the methods we have overidden when building the graph \n",
    "        super(SimpleSynapticNeurons, self).__init__(n, A, B, C, D)\n",
    "           \n",
    "    ########################################################\n",
    "    # Override the parent graph Variables and placeholders #\n",
    "    ########################################################    \n",
    "    def get_vars_and_ph(self):\n",
    "        \n",
    "        # Get parent grah variables and placeholders\n",
    "        super(SimpleSynapticNeurons, self).get_vars_and_ph()\n",
    "            \n",
    "        # Input synapse conductance dynamics (increases on each synapse spike)\n",
    "        self.g_in = tf.Variable(tf.zeros(dtype=tf.float32, shape=[self.m]),\n",
    "                                    dtype=tf.float32,\n",
    "                                    name='g_in')\n",
    "\n",
    "        # We need a new placeholder to pass the input synapses behaviour at each timestep\n",
    "        self.syn_has_spiked = tf.placeholder(tf.bool, shape=[self.m])\n",
    "\n",
    "        \n",
    "    #######################################################\n",
    "    # Modify i_op in the graph of operations:             # \n",
    "    #     syn_has_spiked -> g_in_op -> i_op               #\n",
    "    #######################################################\n",
    "    def get_input_ops(self, has_fired_op, v_op):\n",
    "\n",
    "        # First, update synaptic conductance dynamics:\n",
    "        # - increment by one the current factor of synapses that fired\n",
    "        # - decrease by tau the conductance dynamics in any case\n",
    "        g_in_update_op = tf.where(self.syn_has_spiked,\n",
    "                                  tf.add(self.g_in, tf.ones(shape=self.g_in.shape)),\n",
    "                                  tf.subtract(self.g_in, tf.multiply(self.dt,tf.divide(self.g_in, self.tau))))\n",
    "\n",
    "        # Update the g_in variable\n",
    "        g_in_op = tf.assign(self.g_in, g_in_update_op)\n",
    "\n",
    "        # We can now evaluate the synaptic input currents\n",
    "        # Isyn = Σ w_in(j)g_in(j)E_in(j) - (Σ w_in(j)g_in(j)).v(t)\n",
    "        i_op = tf.subtract(tf.einsum('nm,m->n', tf.constant(self.W_in), tf.multiply(g_in_op, tf.constant(self.E_in))),\n",
    "                           tf.multiply(tf.einsum('nm,m->n', tf.constant(self.W_in), g_in_op), v_op))\n",
    "\n",
    "        # Store a reference to this operation for easier retrieval\n",
    "        self.input = i_op\n",
    "        \n",
    "        return i_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stimulate a neuron with $100$ synapses firing at $2 Hz$ between $200$ and $700 ms$.\n",
    "\n",
    "Every millisecond, there are $0.001 * 2 * 100 = 0.2$ synapse spikes as an average.\n",
    "\n",
    "In other words, a synapse spike occurs every $5 ms$ as an average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Simulation #\n",
    "##############\n",
    "\n",
    "# Array of input current values\n",
    "I_in = []\n",
    "# Array of evaluated membrane potential values\n",
    "v_out = []\n",
    "# Duration of the simulation in ms\n",
    "T = 1000\n",
    "# Duration of each time step in ms\n",
    "dt = 0.5\n",
    "# Number of iterations = T/dt\n",
    "steps = range(int(T / dt))\n",
    "# Number of neurons\n",
    "n = 1\n",
    "# Number of synapses\n",
    "m = 100\n",
    "# Synapses firing rate\n",
    "frate = 0.002\n",
    "\n",
    "# Instantiate the population of synaptic neurons\n",
    "neurons = SimpleSynapticNeurons(n, m)\n",
    "    \n",
    "with tf.Session(graph=neurons.graph) as sess:\n",
    "\n",
    "    # Initialize v and u to their default values \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Run the simulation at each time step\n",
    "    for step in steps:\n",
    "        \n",
    "        t = step * dt\n",
    "        # We generate random spikes on the input synapses between 200 and 700 ms\n",
    "        if t > 200 and t < 700:\n",
    "            # Generate a random matrix\n",
    "            r = np.random.uniform(0,1,(m))\n",
    "            # A synapse has spiked when r is lower than the spiking rate\n",
    "            p_syn_spike = r < frate * dt\n",
    "        else:\n",
    "            # No synapse activity during that period\n",
    "            p_syn_spike = np.zeros((m), dtype=bool)\n",
    "        \n",
    "        feed = {neurons.syn_has_spiked: p_syn_spike, neurons.dt: [dt]}\n",
    "\n",
    "        # Run the graph corresponding to our update ops, with our parameters \n",
    "        i, v, u = sess.run([neurons.input, neurons.potential, neurons.recovery], feed_dict=feed)\n",
    "        \n",
    "        # Store values\n",
    "        I_in.append((t,i))\n",
    "        v_out.append((t,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] =(12,6)\n",
    "# Draw the input current and the membrane potential\n",
    "plt.figure()\n",
    "plt.title('Input current')\n",
    "plt.ylabel('Current (mA)')\n",
    "plt.xlabel('Time (msec)')\n",
    "_, i_mean = np.mean(np.array(I_in)[int(200/dt):int(700/dt),:], axis=0)\n",
    "plt.axhline(y=i_mean, color='y', linestyle='--')\n",
    "plt.plot(*zip(*I_in))\n",
    "plt.figure()\n",
    "plt.title('Neuron response')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.plot(*zip(*v_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The synaptic input current oscillates around a mean value of approximately $10 mA$.\n",
    "\n",
    "Due to the increased input current, the neuron spikes faster than in the previous stimulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Simulate 1000 neurons with synaptic input\n",
    "\n",
    "Each neuron is either:\n",
    "\n",
    "- an inhibitory fast-spiking neuron $(a=0.1, d=2.0)$,\n",
    "- or an excitatory regular spiking neuron $(a=0.02, d=8.0)$.\n",
    "\n",
    "with a proportion of $20$ % inhibitory.\n",
    "\n",
    "We therefore define a random uniform vector p on $[0,1]$, and condition the a and d vectors of our neuron population on p.\n",
    "\n",
    "$$a[p<0.2] = 0.1, a[p >=0.2] = 0.02$$\n",
    "\n",
    "$$d[p<0.2] = 2.0, d[p >=0.2] = 8.0$$\n",
    "\n",
    "Each neuron is randomly connected with $10$ % of the input synapses, and thus receives an input synapse spike every $50 ms$ as an average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Simulation #\n",
    "##############\n",
    "\n",
    "# Duration of the simulation in ms\n",
    "T = 1000\n",
    "# Duration of each time step in ms\n",
    "dt = 0.5\n",
    "# Number of iterations = T/dt\n",
    "steps = int(T / dt)\n",
    "# Number of neurons\n",
    "n = 1000\n",
    "# Number of synapses\n",
    "m = 100\n",
    "# Synapses firing rate\n",
    "frate = 0.002\n",
    "\n",
    "# Array of input current values\n",
    "I_in = []\n",
    "# Array of evaluated membrane potential values\n",
    "v_out = np.zeros((steps,n))\n",
    "    \n",
    "# Generate a random distribution for our neurons\n",
    "p_neurons = np.random.uniform(0,1,(n))\n",
    "    \n",
    "# Assign neuron parameters based on the probability\n",
    "a = np.full((n), 0.02, dtype=np.float32)\n",
    "a[p_neurons < 0.2] = 0.1\n",
    "d = np.full((n), 8.0, dtype=np.float32)\n",
    "d[p_neurons < 0.2] = 2.0\n",
    "    \n",
    "# Randomly connect 10% of the neurons to the input synapses\n",
    "p_syn = np.random.uniform(0,1,(n,m))\n",
    "w_in = np.zeros((n,m), dtype=np.float32)\n",
    "w_in[ p_syn < 0.1 ] = 0.07\n",
    "    \n",
    "# Instantiate the population of synaptic neurons\n",
    "neurons = SimpleSynapticNeurons(n, m, A=a, D=d, W_in=w_in)\n",
    "\n",
    "with tf.Session(graph=neurons.graph) as sess:\n",
    "\n",
    "    # Initialize global variables to their default values \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Run the simulation at each time step\n",
    "    for t in range(steps):\n",
    "        \n",
    "        # We generate random spikes on the input synapses between 200 and 700 ms\n",
    "        if t * dt > 200 and t * dt < 700:\n",
    "            # Generate a random matrix\n",
    "            r = np.random.uniform(0,1,(m))\n",
    "            # A synapse has spiked when r is lower than the spiking rate\n",
    "            p_syn_spike = r < frate * dt\n",
    "        else:\n",
    "            # No synapse activity during that period\n",
    "            p_syn_spike = np.zeros((m), dtype=bool)\n",
    "        \n",
    "        feed = {neurons.syn_has_spiked: p_syn_spike, neurons.dt: [dt]}\n",
    "\n",
    "        # Run the graph corresponding to our update ops, with our parameters \n",
    "        i, v, u = sess.run([neurons.input, neurons.potential, neurons.recovery], feed_dict=feed)\n",
    "        \n",
    "        # Store values\n",
    "        v_out[t, :] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of displaying the membrane potentials, we just plot the neuron spikes for inhibitory (blue) and excitatory (yellow) neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] =(12,6)\n",
    "# Split between inhibitory and excitatory\n",
    "inh_v_out = np.where(p_neurons < 0.2, v_out, 0)\n",
    "exc_v_out = np.where(p_neurons >= 0.2, v_out, 0)\n",
    "# Identify spikes\n",
    "inh_spikes = np.argwhere(inh_v_out == 35.0)\n",
    "exc_spikes = np.argwhere(exc_v_out == 35.0)\n",
    "# Display spikes over time\n",
    "plt.axis([0, T, 0, n])\n",
    "plt.title('Inhibitory and excitatory spikes')\n",
    "plt.ylabel('Neurons')\n",
    "plt.xlabel('Time (msec)')\n",
    "# Plot inhibitory spikes\n",
    "steps, neurons = inh_spikes.T\n",
    "plt.scatter(steps*dt, neurons, s=3)\n",
    "# Plot excitatory spikes\n",
    "steps, neurons = exc_spikes.T\n",
    "plt.scatter(steps*dt, neurons, s=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neurons spike in 'stripes' at somehow regular intervals, with a bit of dispersion.\n",
    "\n",
    "The neuron dynamics seem to act as a regulator to the synaptic 'noise'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Simulate 1000 neurons with recurrent connections\n",
    "\n",
    "A neuron i is sparsely (with probability $prc = 0.1$) connected to a neuron j.\n",
    "\n",
    "Thus neuron i receives an additional current $Isyn(i)$ of the same form as the synaptic input:\n",
    "\n",
    "$$Isyn(i) = \\sum_{j}w(i,j)g(j)(E(j) -v(t))$$\n",
    "\n",
    "Weights $w$ are Gamma distributed (scale $0.003$, shape $2$).\n",
    "\n",
    "Inhibitory to excitatory connections are twice as strong.\n",
    "\n",
    "$E(j)$ is set to $-85$ for inhibitory neurons, $0$ otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# A class representing a population of simple neurons with synaptic inputs\n",
    "#\n",
    "class SimpleSynapticRecurrentNeurons(SimpleSynapticNeurons):\n",
    "    \n",
    "    def __init__(self, n=1, m=100, A=None, B=None, C=None, D=None, W_in=None, W=None, E=None):\n",
    "\n",
    "        # Additional model parameters\n",
    "        self.W = W\n",
    "        self.E = E\n",
    "        \n",
    "        # Call the parent contructor\n",
    "        super(SimpleSynapticRecurrentNeurons, self).__init__(n, m, A, B, C, D, W_in)\n",
    "\n",
    "    ########################################################\n",
    "    # Override the parent graph Variables and placeholders #\n",
    "    ########################################################    \n",
    "    def get_vars_and_ph(self):\n",
    "        \n",
    "        # Get parent grah variables and placeholders\n",
    "        super(SimpleSynapticRecurrentNeurons, self).get_vars_and_ph()\n",
    "            \n",
    "        # Recurrent synapse conductance dynamics (increases on each synapse spike)\n",
    "        self.g = tf.Variable(tf.zeros(dtype=tf.float32, shape=[self.n]),\n",
    "                             dtype=tf.float32,\n",
    "                             name='g')\n",
    "\n",
    "    #######################################################\n",
    "    # Modify i_op in the graph of operations:             # \n",
    "    #     syn_has_spiked -> i_in_op,i_rec_op -> i_op      #\n",
    "    #######################################################\n",
    "    def get_input_ops(self, has_fired_op, v_op):\n",
    "\n",
    "        # First, update recurrent conductance dynamics:\n",
    "        # - increment by one the current factor of synapses that fired\n",
    "        # - decrease by tau the conductance dynamics in any case\n",
    "        g_update_op = tf.where(has_fired_op,\n",
    "                               tf.add(self.g, tf.ones(shape=self.g.shape)),\n",
    "                               tf.subtract(self.g, tf.multiply(self.dt, tf.divide(self.g, self.tau))))\n",
    "        \n",
    "        # Update the g variable\n",
    "        g_op = tf.assign(self.g, g_update_op)\n",
    "\n",
    "        # We can now evaluate the recurrent conductance\n",
    "        # I_rec = Σ wjgj(Ej -v(t))\n",
    "        i_rec_op = tf.einsum('ij,j->i', tf.constant(self.W), tf.multiply(g_op, tf.subtract(tf.constant(self.E), v_op)))\n",
    "\n",
    "        # Get the synaptic input currents from parent\n",
    "        i_in_op = super(SimpleSynapticRecurrentNeurons, self).get_input_ops(has_fired_op, v_op)\n",
    "        \n",
    "        # The actual current is the sum of both currents\n",
    "        i_op = i_in_op + i_rec_op\n",
    "\n",
    "        # Store a reference to this operation for easier retrieval\n",
    "        self.input = i_op\n",
    "        \n",
    "        return i_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Simulation #\n",
    "##############\n",
    "\n",
    "# Duration of the simulation in ms\n",
    "T = 1000\n",
    "# Duration of each time step in ms\n",
    "dt = 0.5\n",
    "# Number of iterations = T/dt\n",
    "steps = int(T / dt)\n",
    "# Number of neurons\n",
    "n = 1000\n",
    "# Number of synapses\n",
    "m = 100\n",
    "# Synapses firing rate\n",
    "frate = 0.002\n",
    "\n",
    "# Array of input current values\n",
    "I_in = []\n",
    "# Array of evaluated membrane potential values\n",
    "v_out = np.zeros((steps,n))\n",
    "    \n",
    "# Generate a random distribution for our neurons\n",
    "p_neurons = np.random.uniform(0,1,(n))\n",
    "    \n",
    "# Assign neuron parameters based on the probability\n",
    "a = np.full((n), 0.02, dtype=np.float32)\n",
    "a[p_neurons < 0.2] = 0.1\n",
    "d = np.full((n), 8.0, dtype=np.float32)\n",
    "d[p_neurons < 0.2] = 2.0\n",
    "\n",
    "# Randomly connect 10% of the neurons to the input synapses\n",
    "p_syn = np.random.uniform(0,1,(n,m))\n",
    "w_in = np.zeros((n,m), dtype=np.float32)\n",
    "w_in[ p_syn < 0.1 ] = 0.07\n",
    "    \n",
    "# Randomly distribute recurrent connections\n",
    "w = np.zeros((n,n),  dtype=np.float32)\n",
    "p_reccur = np.random.uniform(0,1,(n,n))\n",
    "w[p_reccur < 0.1] = np.random.gamma(2, 0.003, size=w[p_reccur < 0.1].shape)\n",
    "# Identify inhibitory to excitatory connections (receiving end is in row)\n",
    "inh_2_exc = np.ix_(p_neurons >= 0.2, p_neurons < 0.2)\n",
    "# Increase the strength of these connections\n",
    "w[ inh_2_exc ] = 2* w[ inh_2_exc]\n",
    "\n",
    "# Only inhibitory neurons have E=-85 mv\n",
    "e = np.zeros((n), dtype=np.float32)\n",
    "e[p_neurons<0.2] = -85.0\n",
    "\n",
    "# Instantiate the population of synaptic neurons\n",
    "neurons = SimpleSynapticRecurrentNeurons(n, m, A=a, D=d, W_in=w_in, W=w, E=e)\n",
    "\n",
    "with tf.Session(graph=neurons.graph) as sess:\n",
    "\n",
    "    # Initialize v and u to their default values \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Run the simulation at each time step\n",
    "    for t in range(steps):\n",
    "        \n",
    "        # We generate random spikes on the input synapses between 200 and 700 ms\n",
    "        if t * dt > 200 and t * dt < 700:\n",
    "            # Generate a random matrix\n",
    "            r = np.random.uniform(0,1,(m))\n",
    "            # A synapse has spiked when r is lower than the spiking rate\n",
    "            p_syn_spike = r < frate * dt\n",
    "        else:\n",
    "            # No synapse activity during that period\n",
    "            p_syn_spike = np.zeros((m), dtype=bool)\n",
    "        \n",
    "        feed = {neurons.syn_has_spiked: p_syn_spike, neurons.dt: [dt]}\n",
    "\n",
    "        # Run the graph corresponding to our update ops, with our parameters \n",
    "        i, v, u = sess.run([neurons.input, neurons.potential, neurons.recovery], feed_dict=feed)\n",
    "        \n",
    "        # Store values\n",
    "        v_out[t, :] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again plot the neuron spikes for inhibitory (blue) and excitatory (yellow) neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] =(12,6)\n",
    "# Split between inhibitory and excitatory\n",
    "inh_v_out = np.where(p_neurons < 0.2, v_out, 0)\n",
    "exc_v_out = np.where(p_neurons >= 0.2, v_out, 0)\n",
    "# Identify spikes\n",
    "inh_spikes = np.argwhere(inh_v_out == 35.0)\n",
    "exc_spikes = np.argwhere(exc_v_out == 35.0)\n",
    "# Display spikes over time\n",
    "plt.axis([0, T, 0, n])\n",
    "plt.title('Inhibitory and excitatory spikes')\n",
    "plt.ylabel('Neurons')\n",
    "plt.xlabel('Time (msec)')\n",
    "# Plot inhibitory spikes\n",
    "steps, neurons = inh_spikes.T\n",
    "plt.scatter(steps*dt, neurons, s=3)\n",
    "# Plot excitatory spikes\n",
    "steps, neurons = exc_spikes.T\n",
    "plt.scatter(steps*dt, neurons, s=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition of recurrent connections has drastically reduced the dispersion of the neuron spikes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
