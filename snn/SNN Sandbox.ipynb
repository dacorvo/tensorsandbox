{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating spiking neurons with Tensorflow\n",
    "\n",
    "In this notebook, we try to simulate a population of spiking neurons using Tensorflow.\n",
    "\n",
    "This exercise is based on an equivalent exercise using [Matlab](http://www.mjrlab.org/wp-content/uploads/2014/05/CSHA_matlab_2012.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking neuron model\n",
    "\n",
    "The neuron model is based on [\"Simple model on spiking neuron\"](http://www.izhikevich.org/publications/spikes.htm), by Eugene M. Izhikevich.\n",
    "\n",
    "<img src=\"izhik.gif\">\n",
    "\n",
    "Electronic version of the figure and reproduction permissions are freely available at www.izhikevich.com\n",
    "\n",
    "The behaviour of the neuron is determined by its membrane potential v that increases over time when it is stimulated by an input current I.\n",
    "Whenever the membrane potential reaches the spiking threshold, the membrane potential is reset.\n",
    "\n",
    "The membrane potential increase is mitigated by an adversary recovery effect defined by the u variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow doesn't support differential equations, so we need to approximate the evolution of the membrane potential and\n",
    "membrane recovery by evaluating their variations over small time intervals dt:\n",
    "\n",
    "dv = 0.04v^2 + 5v + 140 -u + I\n",
    "\n",
    "du = a(bv -u)\n",
    "\n",
    "We can then apply the variations by multiplying by the time interval dt:\n",
    "\n",
    "v += dv.dt\n",
    "\n",
    "u += dv.du\n",
    "    \n",
    "As stated in the model, the 0.04, 5 and 140 values have been defined so that v is in mV, I is in A and t in ms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a single neuron with injected current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# A class representing a population of simple neurons\n",
    "#\n",
    "class SimpleNeurons(object):\n",
    "    \n",
    "    def __init__(self, n=1):\n",
    "\n",
    "        ####################\n",
    "        # Model parameters #\n",
    "        ####################\n",
    "        # Scale of the membrane recovery (lower values lead to slow recovery)\n",
    "        self.A = 0.02\n",
    "        # Sensitivity of recovery towards membrane potential (higher values lead to higher firing rate)\n",
    "        self.B = 0.2\n",
    "        # Membrane voltage reset value\n",
    "        self.C = -65.0\n",
    "        # Membrane recovery 'boost' after a spike\n",
    "        self.D = 8   \n",
    "        # Spiking threshold\n",
    "        self.SPIKING_THRESHOLD = 35.0\n",
    "\n",
    "        ##############################\n",
    "        # Variables and placeholders #\n",
    "        ##############################\n",
    "        # Membrane potential\n",
    "        # All neurons start at the reset value C\n",
    "        self.v = tf.Variable(tf.constant(self.C, dtype=tf.float32, shape=[n]),\n",
    "                            dtype=tf.float32,\n",
    "                            name='v')\n",
    "\n",
    "        # Membrane recovery\n",
    "        # All neurons start with a value of B * C\n",
    "        self.u = tf.Variable(tf.constant(self.B*self.C, dtype=tf.float32, shape=[n]),\n",
    "                             dtype=tf.float32,\n",
    "                             name='u')\n",
    "\n",
    "        # We need a placeholder to pass the input current\n",
    "        self.I = tf.placeholder(tf.float32, shape=[n])\n",
    "\n",
    "        # We also need a placeholder to pass the length of the time interval\n",
    "        self.dt = tf.placeholder(tf.float32, shape=[n])\n",
    "\n",
    "    #######################################################\n",
    "    # Define the graph of operations to update v and u:   # \n",
    "    # has_fired_op                                        # \n",
    "    #   -> (v_reset_op, u_rest_op)                        #\n",
    "    #      -> (dv_op, du_op)          <- I_op             #\n",
    "    #        -> (v_op, u_op)                              #\n",
    "    # We only need to return the leaf operations as their #\n",
    "    # graph include the others.                           #\n",
    "    #######################################################\n",
    "    def get_ops(self):\n",
    "        \n",
    "        has_fired_op, v_reset_op, u_reset_op = self.get_reset_ops()\n",
    "\n",
    "        I_op = tf.add(self.I, 0.0)\n",
    "        \n",
    "        return self.get_update_ops(has_fired_op, v_reset_op, u_reset_op, I_op)\n",
    "\n",
    "    def get_reset_ops(self):\n",
    "        \n",
    "        # Evaluate which neurons have reached the spiking threshold\n",
    "        has_fired_op = tf.greater_equal(self.v, tf.constant(self.SPIKING_THRESHOLD))\n",
    "    \n",
    "        # Neurons that have spiked must be reset, others simply evolve from their initial value\n",
    "\n",
    "        # Membrane potential is reset to C\n",
    "        v_reset_op = tf.where(has_fired_op, tf.constant(self.C, shape=self.v.shape), self.v)\n",
    "\n",
    "        # Membrane recovery is increased by D \n",
    "        u_reset_op = tf.where(has_fired_op, tf.add(self.u, self.D), self.u)\n",
    "\n",
    "        return (has_fired_op, v_reset_op, u_reset_op)\n",
    "        \n",
    "    def get_update_ops(self, has_fired_op, v_reset_op, u_reset_op, I_op):\n",
    "\n",
    "        # Evaluate membrane potential increment for the considered time interval\n",
    "        # dv = 0 if the neuron fired, dv = 0.04v*v + 5v + 140 + I -u otherwise\n",
    "        dv_op = tf.where(has_fired_op,\n",
    "                         tf.zeros(self.v.shape),\n",
    "                         tf.subtract(tf.add_n([tf.multiply(tf.square(v_reset_op), 0.04),\n",
    "                                               tf.multiply(v_reset_op, 5.0),\n",
    "                                               tf.constant(140.0, shape=self.v.shape),\n",
    "                                               I_op]),\n",
    "                                     self.u))\n",
    "            \n",
    "        # Evaluate membrane recovery decrement for the considered time interval\n",
    "        # du = 0 if the neuron fired, du = a*(b*v -u) otherwise\n",
    "        du_op = tf.where(has_fired_op,\n",
    "                         tf.zeros(self.v.shape),\n",
    "                         tf.multiply(self.A, tf.subtract(tf.multiply(self.B, v_reset_op), u_reset_op)))\n",
    "    \n",
    "        # Increment membrane potential, and clamp it to the spiking threshold\n",
    "        # v += dv * dt\n",
    "        v_op = tf.assign(self.v, tf.minimum(tf.constant(self.SPIKING_THRESHOLD, shape=self.v.shape),\n",
    "                                                 tf.add(v_reset_op, tf.multiply(dv_op, self.dt))))\n",
    "\n",
    "        # Decrease membrane recovery\n",
    "        u_op = tf.assign(self.u, tf.add(u_reset_op, tf.multiply(du_op, self.dt)))\n",
    "\n",
    "        return (v_op, u_op)\n",
    "\n",
    "##############\n",
    "# Simulation #\n",
    "##############\n",
    "\n",
    "# Number of neurons\n",
    "n = 1\n",
    "# Array of input current values\n",
    "I_in = []\n",
    "# Array of evaluated membrane potential values\n",
    "v_out = []\n",
    "# Duration of the simulation in ms\n",
    "T = 1000\n",
    "# Duration of each time step in ms\n",
    "dt = 0.5\n",
    "# Number of iterations = T/dt\n",
    "steps = range(int(T / dt))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Instantiate the population of neuron (here a single one)\n",
    "    neurons = SimpleNeurons(n)\n",
    "    v_op, u_op = neurons.get_ops()\n",
    "\n",
    "    # Initialize global variables to their default values \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Run the simulation at each time step\n",
    "    for t in steps:\n",
    "        \n",
    "        # We generate a current step of 7 A between 200 and 700 ms\n",
    "        if t * dt > 200 and t * dt < 700:\n",
    "            i_in = 7.0\n",
    "        else:\n",
    "            i_in = 0.0\n",
    "            \n",
    "        # Create the dictionary of parameters to use for this time step\n",
    "        feed = {neurons.I: np.full((n), i_in), neurons.dt: np.full((n), dt)}\n",
    "        \n",
    "        # Run the graph corresponding to our update ops, passing our parameters\n",
    "        sess.run([v_op, u_op], feed_dict=feed)\n",
    "        \n",
    "        # Store values\n",
    "        I_in.append(i_in)\n",
    "        v_out.append(neurons.v.eval())\n",
    "\n",
    "# Draw the input current and the membrane potential\n",
    "%matplotlib inline\n",
    "plt.plot([np.asscalar(x) for x in v_out])\n",
    "plt.plot([x for x in I_in])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Simulate a single neuron with synaptic input\n",
    "\n",
    "It is a simple variation of the previous experiment, where the input current is the composition of currents coming from several synapses (typically here, a hundred).\n",
    "\n",
    "The formula for evaluating the synaptic current corresponds to the weighted sum of the input current generated by each synapse:\n",
    "\n",
    "Isyn = Σ wj.Isyn(j)\n",
    "\n",
    "The current Isyn(j) generated by each synapse is the multiplication of:\n",
    "- a linear response to the membrane potential, with a target objective of potential Ej: (Ej -v)\n",
    "- a conductance dynamics parameter, that is an exponential function gj that is defined by a differential equation.\n",
    "\n",
    "dgj/dt = gj/tau\n",
    "\n",
    "Each input synapse emits a spike following a poisson distribution of frequency frate. The probability that a neuron fires during the time interval dt is thus frate.dt.\n",
    "\n",
    "To simulate the neuron, we draw random numbers r in the [0,1] interval at each timestep, and is the number r is less than frate.dt, we generate a synapse spike by increasing the conductance dynamics for that synapse:\n",
    "\n",
    "gj = gj + 1\n",
    "\n",
    "The complete synaptic current formula at each timestep is:\n",
    "\n",
    "Isyn = Σ wjgj(Ej -v(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# A class representing a population of simple neurons with synaptic inputs\n",
    "#\n",
    "class SimpleSynapticNeurons(SimpleNeurons):\n",
    "    \n",
    "    def __init__(self, n=1, m=100):\n",
    "\n",
    "        # Call the parent contructor\n",
    "        super(SimpleSynapticNeurons, self).__init__(n)\n",
    "        \n",
    "        # Additional model parameters\n",
    "        self.tau = 10.0\n",
    "        self.W = tf.constant(0.07, shape=(n,m), dtype=np.float32)\n",
    "        self.E = np.zeros((n,m), dtype=np.float32)\n",
    "\n",
    "        # Input synapse conductance dynamics (increases on each synapse spike)\n",
    "        self.g = tf.Variable(tf.zeros(dtype=tf.float32, shape=[n, m]),\n",
    "                             dtype=tf.float32,\n",
    "                             name='g')\n",
    "\n",
    "        # We need a placeholder to pass the input synapses behaviour at each timestep\n",
    "        self.syn_has_spiked = tf.placeholder(tf.bool, shape=[n,m])\n",
    "\n",
    "    #######################################################\n",
    "    # Define the graph of operations to update v and u:   # \n",
    "    # has_fired_op                                        # \n",
    "    #   -> (v_reset_op, u_rest_op)                        #\n",
    "    #      -> (dv_op, du_op)          <- I_op             #\n",
    "    #        -> (v_op, u_op)                              #\n",
    "    # We only need to return the leaf operations as their #\n",
    "    # graph include the others.                           #\n",
    "    #######################################################\n",
    "    def get_ops(self):\n",
    "        \n",
    "        # First, update synaptic conductance dynamics:\n",
    "        # - increment by one the current factor of synapses that fired\n",
    "        # - decrease by tau the conductance dynamics in any case\n",
    "        g_update_op = tf.where(self.syn_has_spiked,\n",
    "                               tf.add(self.g, tf.ones(shape=self.g.shape)),\n",
    "                               tf.subtract(self.g, tf.divide(self.g, tf.constant(self.tau, shape=self.g.shape))))\n",
    "\n",
    "        # Update the g variable\n",
    "        g_op = tf.assign(self.g, g_update_op)\n",
    "\n",
    "        # Get reset ops from parent model\n",
    "        has_fired_op, v_reset_op, u_reset_op = self.get_reset_ops()\n",
    "\n",
    "        # We can now evaluate the synaptic input currents\n",
    "        # Isyn = Σ wj.isyn(j) = Σ wjgj(Ej -v(t))\n",
    "        I_op = tf.einsum('nm,nm,nm->n', self.W, g_op, tf.subtract(self.E, v_reset_op))\n",
    "        \n",
    "        # Finally, get v and u update operations\n",
    "        v_op, u_op = self.get_update_ops(has_fired_op, v_reset_op, u_reset_op, I_op)\n",
    "        \n",
    "        return (g_op, v_op, u_op)\n",
    "\n",
    "\n",
    "##############\n",
    "# Simulation #\n",
    "##############\n",
    "\n",
    "# Array of input current values\n",
    "I_in = []\n",
    "# Array of evaluated membrane potential values\n",
    "v_out = []\n",
    "# Duration of the simulation in ms\n",
    "T = 1000\n",
    "# Number of iterations = T/dt\n",
    "steps = range(int(T / dt))\n",
    "# Number of neurons\n",
    "n = 1\n",
    "# Number of synapses\n",
    "m = 100\n",
    "# Synapses firing rate\n",
    "frate = 0.002\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Instantiate the population of synaptic neurons\n",
    "    neurons = SimpleSynapticNeurons(n, m)\n",
    "\n",
    "    # Initialize v and u to their default values \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # build the graph allowing us to update both v and u\n",
    "    g_out_op, v_out_op, u_out_op = neurons.get_ops()\n",
    "\n",
    "    # Run the simulation at each time step\n",
    "    for t in steps:\n",
    "        \n",
    "        # We generate a current step of 7 A between 200 and 700 ms\n",
    "        if t * dt > 200 and t * dt < 700:\n",
    "            # Generate a random matrix\n",
    "            r = np.random.uniform(0,1,(n, m))\n",
    "            # A synapse has spiked when r is lower than the spiking rate\n",
    "            p = r < frate * dt\n",
    "        else:\n",
    "            # No synapse activity during that period\n",
    "            p = np.zeros((n,m), dtype=bool)\n",
    "        \n",
    "        feed = {neurons.syn_has_spiked: p, neurons.dt: np.full((n), dt)}\n",
    "\n",
    "        # Run the graph corresponding to our update ops, with our parameters \n",
    "        sess.run([g_out_op, v_out_op, u_out_op], feed_dict=feed)\n",
    "        \n",
    "        # Store values\n",
    "        v_out.append(neurons.v.eval())\n",
    "\n",
    "# Draw the input current and the membrane potential\n",
    "%matplotlib inline\n",
    "plt.plot([np.asscalar(x) for x in v_out])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
