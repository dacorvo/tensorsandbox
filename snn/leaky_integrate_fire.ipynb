{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaky integrate and fire neuron with Tensorflow\n",
    "\n",
    "In this notebook, we will demontrate how to simulate a Leaky integrate and fire neuron using tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky-integrate-and-fire model\n",
    "\n",
    "This notebook uses the model described in [ยง 4.1 of \"Spiking Neuron Models\", by Gerstner and Kistler (2002)](http://lcn.epfl.ch/~gerstner/SPNM/node26.html#SECTION02311000000000000000).\n",
    "\n",
    "The leaky integrate-and-fire (LIF) neuron is probably one of the simplest spiking neuron models, but it is still very popular due to the ease with which it can be analyzed and simulated.\n",
    "\n",
    "The basic circuit of an integrate-and-fire model consists of a capacitor C in parallel with a resistor R driven by a current I(t):\n",
    "\n",
    "<img src=\"gerstner.gif\">\n",
    "\n",
    "The driving current can be split into two components, $I(t) = IR + IC$. \n",
    "\n",
    "The first component is the resistive current $IR$ which passes through the linear resistor $R$.\n",
    "\n",
    "It can be calculated from Ohm's law as $IR = \\frac{u}{R}$ where $u$ is the voltage across the resistor.\n",
    "\n",
    "The second component $IC$ charges the capacitor $C$.\n",
    "\n",
    "From the definition of the capacity as $C = \\frac{q}{u}$ (where $q$ is the charge and $u$ the voltage), we find a capacitive current $IC = C\\frac{du}{dt}$. Thus:\n",
    "\n",
    "$$I(t) = \\frac{u(t)}{R} + C\\frac{du}{dt}$$\n",
    "\n",
    "By multiplying the equation by $R$ and introducing the time constant $\\tau_{m} = RC$ this yields the standard form:\n",
    "\n",
    "$$\\tau_{m}\\frac{du}{dt}=-u(t) + RI(t)$$\n",
    "\n",
    "where $u(t)$ represents the membrane potential at time $t$, $\\tau_{m}$ is the membrane time constant and $R$ is the\n",
    "membrane resistance.\n",
    "\n",
    "When the membrane potential reaches the spiking threshold $u_{thresh}$, the neuron 'spikes' and enters a resting state for a duration $\\tau_{rest}$.\n",
    "\n",
    "During the resting perdiod the membrane potential remains constant a $u_{rest}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a single LIF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These imports will be used in the notebook\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A basic LIF neuron\n",
    "class LIFNeuron(object):\n",
    "    \n",
    "    def __init__(self, u_rest=0.0, u_thresh=1.0, tau_rest=4.0, r=1.0, tau=10.0):\n",
    "        \n",
    "        # Membrane resting potential in mV\n",
    "        self.u_rest = u_rest\n",
    "        # Membrane threshold potential in mV\n",
    "        self.u_thresh = u_thresh\n",
    "        # Duration of the resting period in ms\n",
    "        self.tau_rest = tau_rest\n",
    "        # Membrane resistance in Ohm\n",
    "        self.r = r\n",
    "        # Membrane time constant in ms\n",
    "        self.tau = tau\n",
    "        \n",
    "        # Instantiate a graph for this neuron\n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        # Build the graph\n",
    "        with self.graph.as_default():\n",
    "        \n",
    "            # Variables and placeholders\n",
    "            self.get_vars_and_ph()\n",
    "            \n",
    "            # Operations\n",
    "            self.input = self.get_input_op()\n",
    "            self.potential = self.get_potential_op()\n",
    "            # Note that input is a prerequisite of potential, so it will\n",
    "            # always be evaluated when potential is\n",
    "            \n",
    "    # Variables and placeholders\n",
    "    def get_vars_and_ph(self):\n",
    "\n",
    "        # The current membrane potential\n",
    "        self.u = tf.Variable(self.u_rest, dtype=tf.float32, name='u')\n",
    "        # The duration left in the resting period (0 most of the time except after a neuron spike)\n",
    "        self.t_rest = tf.Variable(0.0, dtype=tf.float32, name='t_rest')\n",
    "        # Input current\n",
    "        self.i_app = tf.placeholder(dtype=tf.float32, name='i_app')\n",
    "        # The chosen time interval for the stimulation in ms\n",
    "        self.dt = tf.placeholder(dtype=tf.float32, name='dt')\n",
    "\n",
    "    # Evaluate input current\n",
    "    def get_input_op(self):\n",
    "        \n",
    "        return self.i_app\n",
    "        \n",
    "    # Neuron behaviour during integration phase (below threshold)\n",
    "    def get_integrating_op(self):\n",
    "\n",
    "        # Get input current\n",
    "        i_op = self.get_input_op()\n",
    "\n",
    "        # Update membrane potential\n",
    "        du_op = tf.divide(tf.subtract(tf.multiply(self.r, i_op), self.u), self.tau) \n",
    "        u_op = self.u.assign_add(du_op * self.dt)\n",
    "        # Refractory period is 0\n",
    "        t_rest_op = self.t_rest.assign(0.0)\n",
    "        \n",
    "        with tf.control_dependencies([t_rest_op]):\n",
    "            return u_op\n",
    "\n",
    "    # Neuron behaviour during firing phase (above threshold)    \n",
    "    def get_firing_op(self):                  \n",
    "\n",
    "        # Reset membrane potential\n",
    "        u_op = self.u.assign(self.u_rest)\n",
    "        # Refractory period starts now\n",
    "        t_rest_op = self.t_rest.assign(self.tau_rest)\n",
    "\n",
    "        with tf.control_dependencies([t_rest_op]):\n",
    "            return u_op\n",
    "\n",
    "    # Neuron behaviour during resting phase (t_rest > 0)\n",
    "    def get_resting_op(self):\n",
    "\n",
    "        # Membrane potential stays at u_rest\n",
    "        u_op = self.u.assign(self.u_rest)\n",
    "        # Refractory period is decreased by dt\n",
    "        t_rest_op = self.t_rest.assign_sub(self.dt)\n",
    "        \n",
    "        with tf.control_dependencies([t_rest_op]):\n",
    "            return u_op\n",
    "\n",
    "    def get_potential_op(self):\n",
    "        \n",
    "        return tf.case(\n",
    "            [\n",
    "                (self.t_rest > 0.0, self.get_resting_op),\n",
    "                (self.u > self.u_thresh, self.get_firing_op),\n",
    "            ],\n",
    "            default=self.get_integrating_op\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Stimulation by a square input current\n",
    "\n",
    "We stimulate the neuron with three square input currents of vaying intensity: 0.5, 1.2 and 1.5 mA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation with square input currents\n",
    "\n",
    "# Duration of the simulation in ms\n",
    "T = 200\n",
    "# Duration of each time step in ms\n",
    "dt = 1\n",
    "# Number of iterations = T/dt\n",
    "steps = int(T / dt)\n",
    "# Output variables\n",
    "I = []\n",
    "U = []\n",
    "\n",
    "neuron = LIFNeuron()\n",
    "    \n",
    "with tf.Session(graph=neuron.graph) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "\n",
    "    for step in range(steps):\n",
    "        \n",
    "        t = step * dt\n",
    "        # Set input current in mA\n",
    "        if t > 10 and t < 30:\n",
    "            i_app = 0.5\n",
    "        elif t > 50 and t < 100:\n",
    "            i_app = 1.2\n",
    "        elif t > 120 and t < 180:\n",
    "            i_app = 1.5\n",
    "        else:\n",
    "            i_app = 0.0\n",
    "\n",
    "        feed = { neuron.i_app: i_app, neuron.dt: dt}\n",
    "        \n",
    "        u = sess.run(neuron.potential, feed_dict=feed)\n",
    "\n",
    "        I.append(i_app)\n",
    "        U.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the input current and the membrane potential\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot([i for i in I])\n",
    "plt.title('Square input stimuli')\n",
    "plt.ylabel('Input current (I)')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.figure()\n",
    "plt.plot([u for u in U])\n",
    "plt.axhline(y=1.0, color='r', linestyle='-')\n",
    "plt.title('LIF response')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.xlabel('Time (msec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first current step is not sufficient to trigger a spike. The two other trigger several spikes whose frequency increases with the input current."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Stimulation by a random varying input current\n",
    "\n",
    "We now stimulate the neuron with a varying current corresponding to a normal distribution centered of mean 1.5 mA and standard deviation of 1.0 mA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation with random input currents\n",
    "\n",
    "# Duration of the simulation in ms\n",
    "T = 200\n",
    "# Duration of each time step in ms\n",
    "dt = 1\n",
    "# Number of iterations = T/dt\n",
    "steps = int(T / dt)\n",
    "# Output variables\n",
    "I = []\n",
    "U = []\n",
    "\n",
    "neuron = LIFNeuron()\n",
    "    \n",
    "with tf.Session(graph=neuron.graph) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "\n",
    "    for step in range(steps):\n",
    "        \n",
    "        t = step * dt\n",
    "        if t > 10 and t < 180:\n",
    "            i_app = np.random.normal(1.5, 1.0)\n",
    "        else:\n",
    "            i_app = 0.0\n",
    "\n",
    "        feed = { neuron.i_app: i_app, neuron.dt: dt}\n",
    "        \n",
    "        u = sess.run(neuron.potential, feed_dict=feed)\n",
    "        \n",
    "        I.append(i_app)\n",
    "        U.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the input current and the membrane potential\n",
    "plt.figure()\n",
    "plt.plot([i for i in I])\n",
    "plt.title('Random input stimuli')\n",
    "plt.ylabel('Input current (I)')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.figure()\n",
    "plt.plot([u for u in U])\n",
    "plt.axhline(y=1.0, color='r', linestyle='-')\n",
    "plt.title('LIF response')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.xlabel('Time (msec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input current triggers spike at regular intervals: the neuron mostly saturates, each spike being separated by the resting period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Stimulate neuron with synaptic currents\n",
    "\n",
    "We now assume that the neuron is connected to input neurons through $m$ synapses.\n",
    "\n",
    "The contribution of the synapses to the neuron input current is given by the general formula below:\n",
    "\n",
    "$$I =\\sum_{i}^{}w_{i}\\sum_{f}{}I_{syn}(t-t_i^{(f)})$$\n",
    "\n",
    "Where $t_i^{(f)}$ is the time of the f-th spike of the synapse $i$.\n",
    "\n",
    "A typical implementation of the $I_{syn}$ function is:\n",
    "\n",
    "$$I_{syn}(t)=\\frac{q}{\\tau}exp(-\\frac{t}{\\tau})$$\n",
    "\n",
    "where $q$ is the total charge that is injected in a postsynaptic neuron via a synapse with efficacy $w_{j} = 1$.\n",
    "\n",
    "Note that $\\frac{dI_{syn}}{dt}=-\\frac{I_{syn}(t)}{\\tau}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new neuron model derived from the LIF neuron\n",
    "# It takes synaptic spikes as input and remember them over a specified time period\n",
    "class LIFSynapticNeuron(LIFNeuron):\n",
    "    \n",
    "    def __init__(self, n_syn, w, max_spikes=50, u_rest=0.0, u_thresh=1.0, tau_rest=4.0, r=1.0, tau=10.0, q=1.5, tau_syn=10.0):\n",
    "      \n",
    "        # Number of synapses\n",
    "        self.n_syn = n_syn\n",
    "        # Maximum number of spikes we remember\n",
    "        self.max_spikes = max_spikes\n",
    "        # The neuron synaptic 'charge'\n",
    "        self.q = q\n",
    "        # The synaptic time constant (ms)\n",
    "        self.tau_syn = tau_syn\n",
    "        # The synaptic efficacy\n",
    "        self.w = w\n",
    "\n",
    "        super(LIFSynapticNeuron, self).__init__(u_rest, u_thresh, tau_rest, r, tau)\n",
    "    \n",
    "    # Update the parent graph variables and placeholders\n",
    "    def get_vars_and_ph(self):\n",
    "        \n",
    "        # Get parent grah variables and placeholders\n",
    "        super(LIFSynapticNeuron, self).get_vars_and_ph()\n",
    "\n",
    "        # Add ours\n",
    "        \n",
    "        # The history of synaptic spike times for the neuron \n",
    "        self.t_spikes = tf.Variable(tf.constant(-1.0, shape=[self.max_spikes, self.n_syn], dtype=tf.float32))\n",
    "        # The last index used to insert spike times\n",
    "        self.t_spikes_idx = tf.Variable(self.max_spikes-1, dtype=tf.int32)\n",
    "        # A placeholder indicating which synapse spiked in the last time step\n",
    "        self.syn_has_spiked = tf.placeholder(shape=[self.n_syn], dtype=tf.bool)\n",
    "\n",
    "    # Operation to update spike times\n",
    "    def update_spike_times(self):\n",
    "        \n",
    "        # Increase the age of older spikes\n",
    "        old_spikes_op = self.t_spikes.assign_add(tf.where(self.t_spikes >=0,\n",
    "                                                          tf.constant(1.0, shape=[self.max_spikes, self.n_syn]) * self.dt,\n",
    "                                                          tf.zeros([self.max_spikes, self.n_syn])))\n",
    "\n",
    "        # Increment last spike index (modulo max_spikes)\n",
    "        new_idx_op = self.t_spikes_idx.assign(tf.mod(self.t_spikes_idx + 1, self.max_spikes))\n",
    "\n",
    "        # Create a list of coordinates to insert the new spikes\n",
    "        idx_op = tf.constant(1, shape=[self.n_syn], dtype=tf.int32) * new_idx_op\n",
    "        coord_op = tf.stack([idx_op, tf.range(self.n_syn)], axis=1)\n",
    "\n",
    "        # Create a vector of new spike times (non-spikes are assigned a negative time)\n",
    "        new_spikes_op = tf.where(self.syn_has_spiked,\n",
    "                                 tf.constant(0.0, shape=[self.n_syn]),\n",
    "                                 tf.constant(-1.0, shape=[self.n_syn]))\n",
    "        \n",
    "        # Replace older spikes by new ones\n",
    "        return tf.scatter_nd_update(old_spikes_op, coord_op, new_spikes_op)\n",
    "\n",
    "    # Override parent get_input_op method\n",
    "    def get_input_op(self):\n",
    "        \n",
    "        # Update our memory of spike times with the new spikes\n",
    "        t_spikes_op = self.update_spike_times()\n",
    "\n",
    "        # Evaluate synaptic input current for each spike on each synapse\n",
    "        i_syn_op = tf.where(t_spikes_op >=0,\n",
    "                            self.q/self.tau_syn * tf.exp(tf.negative(t_spikes_op/self.tau_syn)),\n",
    "                            t_spikes_op*0.0)\n",
    "\n",
    "        # Add each synaptic current to the input current\n",
    "        i_op =  tf.reduce_sum(self.w * i_syn_op)\n",
    "        \n",
    "        return tf.add(self.i_app, i_op)                             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each synapse spikes according to an independent poisson process at $\\lambda = 20 hz$.\n",
    "\n",
    "We perform a simulation by evaluating the contribution of each synapse to the input current over time.\n",
    "\n",
    "At every time step, we draw a single sample $r$ from a uniform distribution in the $[0,1]$ interval, and if it is lower than\n",
    "the probability of a spike over the time interval (ie $r < \\lambda.dt$) then a spike occurred.\n",
    "\n",
    "Note that this assumes that the chosen time interval is lower than the minimum synapse spiking frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation with synaptic input currents\n",
    "\n",
    "# Duration of the simulation in ms\n",
    "T = 200\n",
    "# Duration of each time step in ms\n",
    "dt = 1\n",
    "# Number of iterations = T/dt\n",
    "steps = int(T / dt)\n",
    "# Number of synapses\n",
    "n_syn = 25\n",
    "# Spiking frequency in Hz\n",
    "f = 20\n",
    "# We need to keep track of input spikes over time\n",
    "syn_has_spiked = np.full((steps,m), False)\n",
    "# We define the synaptic efficacy as a random vector\n",
    "W = np.random.normal(1.0, 0.5, size=m)\n",
    "# Output variables\n",
    "I = []\n",
    "U = []\n",
    "\n",
    "# Instantiate our synaptic LIF neuron, with a memory of 200 events\n",
    "# Note that in practice, a much shorter period is required as the\n",
    "# contribution of each synapse decreases very rapidly\n",
    "neuron = LIFSynapticNeuron(n_syn=n_syn, w=W, max_spikes=200)\n",
    "    \n",
    "with tf.Session(graph=neuron.graph) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "\n",
    "    for step in range(steps):\n",
    "        \n",
    "        t = step * dt\n",
    "        \n",
    "        if t > 10 and t < 180:\n",
    "            r = np.random.uniform(0,1, size=(m))\n",
    "            syn_has_spiked[step,:] = r < f * dt * 1e-3\n",
    "\n",
    "        feed = { neuron.i_app: 0.0, neuron.syn_has_spiked: syn_has_spiked[step], neuron.dt: dt}\n",
    "        i, u = sess.run([neuron.input, neuron.potential], feed_dict=feed)\n",
    "\n",
    "        I.append(i)\n",
    "        U.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw spikes\n",
    "spikes = np.argwhere(syn_has_spiked)\n",
    "t, s = spikes.T\n",
    "plt.figure()\n",
    "plt.axis([0, T, 0, m])\n",
    "plt.title('Synaptic spikes')\n",
    "plt.ylabel('spikes')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.scatter(t, s)\n",
    "# Draw the input current and the membrane potential\n",
    "plt.figure()\n",
    "plt.plot([i for i in I])\n",
    "plt.title('Synaptic input')\n",
    "plt.ylabel('Input current (I)')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.figure()\n",
    "plt.plot([u for u in U])\n",
    "plt.axhline(y=1.0, color='r', linestyle='-')\n",
    "plt.title('LIF response')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.xlabel('Time (msec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neuron spikes when several synapse spike together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
